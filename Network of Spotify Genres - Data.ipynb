{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network of Spotify Genres - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 1st part of the analysis that looks into the network of genre tags in spotify. In this part, I use the Spotify API to download the data and shape it as we need for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import pandas as pd\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import itertools\n",
    "client_credentials_manager = SpotifyClientCredentials('40cd9cd27c7c4689bc36774f5aac188b','10d3a4b01aea4976ac89c831db901a6d')\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager, requests_timeout=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an unbiased and lasrge enough sample of all artists in spotify. Spotify's own account on spotify featuring playlists made my Spotify's staff and algorithms is a good place to start, as they have the most number of public playlists on the platform covering a variety of genres and eras. So first, let's print collect all playlists created by Spotify's team. There's a lot of genre, mood and era specific plalists, along with \"This is:\" playlists that focus on one particular artists big hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = sp.user_playlists('spotify')\n",
    "playlist_ids = []\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        playlist_ids.append(playlist['id'])\n",
    "    if playlists['next']:\n",
    "        playlists = sp.next(playlists)\n",
    "    else:\n",
    "        playlists = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get the data on all the tracks in each of these plalists and collect data on the artists of these tracks as well. we drop all duplicate artists and convert the data into a dataframe with over 37000 artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n"
     ]
    }
   ],
   "source": [
    "trackslist = [] \n",
    "for j,i in enumerate(playlist_ids):\n",
    "#     if j%50 == 0:\n",
    "#         print(j)\n",
    "    tracks = sp.playlist_tracks(i, limit = 100)\n",
    "    trackslist.append(tracks['items'])\n",
    "    while tracks['next']:\n",
    "        tracks = sp.next(tracks)\n",
    "        trackslist.append(tracks['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n"
     ]
    }
   ],
   "source": [
    "tracks = [j['track'] for i in trackslist for j in i]\n",
    "artistids = [j['id'] for i in tracks if i!=None for j in i['artists']]\n",
    "artistids = pd.Series(artistids).drop_duplicates()\n",
    "artistids = artistids.dropna()\n",
    "artists = sp.artists(artistids[:50])['artists']\n",
    "for i in range(50,len(artistids),50):\n",
    "    artists.append(sp.artists(artistids[i:(i+50)])['artists'])\n",
    "artists = artists[:50] + [j for i in artists[50:] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range(len(artists)):\n",
    "        artists[j]['followers'] = artists[j]['followers']['total']\n",
    "artists = pd.DataFrame.from_dict(artists)\n",
    "artists = artists.drop_duplicates(subset = ['uri'])\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we have even more artists in our sample set, I use the artist_related_artists() function, which returns up to 20 related artists for every artist I pass as input. I also shape the data for a different network in the meantime, where, if 2 artists show up as related, we build an edge between them, this is for a network of artists rather than a network of genres. Now I have over 8-k unique artistsin my database with over 4000 unique genre tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37130"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_artists = []\n",
    "for j, i in enumerate(artistids):\n",
    "    related_artists.append(sp.artist_related_artists(i))\n",
    "related_artists = [i for i in related_artists if i!= None]\n",
    "related_artists = [i['artists'] for i in related_artists]\n",
    "len(related_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relart = related_artists\n",
    "for i in range(len(relart)):\n",
    "    if relart[i]!=[]:\n",
    "        for j in range(len(relart[i])):\n",
    "            relart[i][j].update(source_id = artistids.iloc[i])\n",
    "relart = [j for i in relart for j in i]\n",
    "for i in range(len(relart)):\n",
    "    relart[i]['followers'] = relart[i]['followers']['total']\n",
    "relart = pd.DataFrame.from_dict(relart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist_data = pd.merge(artists, relart, left_on = 'id', right_on = 'source_id',suffixes=('_source', '_related'))\n",
    "all_artist_data = all_artist_data.drop_duplicates(subset = ['source_id','id_related'])\n",
    "all_artist_data = all_artist_data[['followers_source','genres_source','id_source','name_source','popularity_source',\n",
    "                                  'uri_source','followers_related', 'genres_related','id_related', 'name_related',\n",
    "                                   'popularity_related','uri_related']]\n",
    "all_artist_data.to_csv('all_artist_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_source</th>\n",
       "      <th>genres_source</th>\n",
       "      <th>id_source</th>\n",
       "      <th>name_source</th>\n",
       "      <th>popularity_source</th>\n",
       "      <th>uri_source</th>\n",
       "      <th>followers_related</th>\n",
       "      <th>genres_related</th>\n",
       "      <th>id_related</th>\n",
       "      <th>name_related</th>\n",
       "      <th>popularity_related</th>\n",
       "      <th>uri_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450747</td>\n",
       "      <td>[pop, post-teen pop]</td>\n",
       "      <td>6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>90</td>\n",
       "      <td>spotify:artist:6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>5250822</td>\n",
       "      <td>[dance pop, pop, pop rock, post-teen pop]</td>\n",
       "      <td>1Hsdzj7Dlq2I7tHP7501T4</td>\n",
       "      <td>Niall Horan</td>\n",
       "      <td>83</td>\n",
       "      <td>spotify:artist:1Hsdzj7Dlq2I7tHP7501T4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7450747</td>\n",
       "      <td>[pop, post-teen pop]</td>\n",
       "      <td>6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>90</td>\n",
       "      <td>spotify:artist:6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>11699509</td>\n",
       "      <td>[dance pop, electropop, pop, post-teen pop, uk...</td>\n",
       "      <td>5ZsFI1h6hIdQRw2ti0hz81</td>\n",
       "      <td>ZAYN</td>\n",
       "      <td>83</td>\n",
       "      <td>spotify:artist:5ZsFI1h6hIdQRw2ti0hz81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7450747</td>\n",
       "      <td>[pop, post-teen pop]</td>\n",
       "      <td>6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>90</td>\n",
       "      <td>spotify:artist:6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>5565051</td>\n",
       "      <td>[dance pop, edm, pop, post-teen pop, tropical ...</td>\n",
       "      <td>5pUo3fmmHT8bhCyHE52hA6</td>\n",
       "      <td>Liam Payne</td>\n",
       "      <td>78</td>\n",
       "      <td>spotify:artist:5pUo3fmmHT8bhCyHE52hA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7450747</td>\n",
       "      <td>[pop, post-teen pop]</td>\n",
       "      <td>6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>90</td>\n",
       "      <td>spotify:artist:6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>3617470</td>\n",
       "      <td>[boy band, dance pop, pop, post-teen pop, vira...</td>\n",
       "      <td>7gAppWoH7pcYmphCVTXkzs</td>\n",
       "      <td>The Vamps</td>\n",
       "      <td>76</td>\n",
       "      <td>spotify:artist:7gAppWoH7pcYmphCVTXkzs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7450747</td>\n",
       "      <td>[pop, post-teen pop]</td>\n",
       "      <td>6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>90</td>\n",
       "      <td>spotify:artist:6KImCVD70vtIoJWnq6nGn3</td>\n",
       "      <td>6174984</td>\n",
       "      <td>[boy band, dance pop, pop, post-teen pop]</td>\n",
       "      <td>5Rl15oVamLq7FbSb0NNBNy</td>\n",
       "      <td>5 Seconds of Summer</td>\n",
       "      <td>86</td>\n",
       "      <td>spotify:artist:5Rl15oVamLq7FbSb0NNBNy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_source         genres_source               id_source  \\\n",
       "0           7450747  [pop, post-teen pop]  6KImCVD70vtIoJWnq6nGn3   \n",
       "1           7450747  [pop, post-teen pop]  6KImCVD70vtIoJWnq6nGn3   \n",
       "2           7450747  [pop, post-teen pop]  6KImCVD70vtIoJWnq6nGn3   \n",
       "3           7450747  [pop, post-teen pop]  6KImCVD70vtIoJWnq6nGn3   \n",
       "4           7450747  [pop, post-teen pop]  6KImCVD70vtIoJWnq6nGn3   \n",
       "\n",
       "    name_source  popularity_source                             uri_source  \\\n",
       "0  Harry Styles                 90  spotify:artist:6KImCVD70vtIoJWnq6nGn3   \n",
       "1  Harry Styles                 90  spotify:artist:6KImCVD70vtIoJWnq6nGn3   \n",
       "2  Harry Styles                 90  spotify:artist:6KImCVD70vtIoJWnq6nGn3   \n",
       "3  Harry Styles                 90  spotify:artist:6KImCVD70vtIoJWnq6nGn3   \n",
       "4  Harry Styles                 90  spotify:artist:6KImCVD70vtIoJWnq6nGn3   \n",
       "\n",
       "   followers_related                                     genres_related  \\\n",
       "0            5250822          [dance pop, pop, pop rock, post-teen pop]   \n",
       "1           11699509  [dance pop, electropop, pop, post-teen pop, uk...   \n",
       "2            5565051  [dance pop, edm, pop, post-teen pop, tropical ...   \n",
       "3            3617470  [boy band, dance pop, pop, post-teen pop, vira...   \n",
       "4            6174984          [boy band, dance pop, pop, post-teen pop]   \n",
       "\n",
       "               id_related         name_related  popularity_related  \\\n",
       "0  1Hsdzj7Dlq2I7tHP7501T4          Niall Horan                  83   \n",
       "1  5ZsFI1h6hIdQRw2ti0hz81                 ZAYN                  83   \n",
       "2  5pUo3fmmHT8bhCyHE52hA6           Liam Payne                  78   \n",
       "3  7gAppWoH7pcYmphCVTXkzs            The Vamps                  76   \n",
       "4  5Rl15oVamLq7FbSb0NNBNy  5 Seconds of Summer                  86   \n",
       "\n",
       "                             uri_related  \n",
       "0  spotify:artist:1Hsdzj7Dlq2I7tHP7501T4  \n",
       "1  spotify:artist:5ZsFI1h6hIdQRw2ti0hz81  \n",
       "2  spotify:artist:5pUo3fmmHT8bhCyHE52hA6  \n",
       "3  spotify:artist:7gAppWoH7pcYmphCVTXkzs  \n",
       "4  spotify:artist:5Rl15oVamLq7FbSb0NNBNy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = artists[[ 'followers', 'genres','id','name','popularity','uri']]\n",
    "artists.to_csv('artist_data_final.csv')\n",
    "all_artist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   followers                                             genres  \\\n",
      "0    5250822          [dance pop, pop, pop rock, post-teen pop]   \n",
      "1   11699509  [dance pop, electropop, pop, post-teen pop, uk...   \n",
      "2    5565051  [dance pop, edm, pop, post-teen pop, tropical ...   \n",
      "3    3617470  [boy band, dance pop, pop, post-teen pop, vira...   \n",
      "4    6174984          [boy band, dance pop, pop, post-teen pop]   \n",
      "\n",
      "                       id                 name  popularity  \\\n",
      "0  1Hsdzj7Dlq2I7tHP7501T4          Niall Horan          83   \n",
      "1  5ZsFI1h6hIdQRw2ti0hz81                 ZAYN          83   \n",
      "2  5pUo3fmmHT8bhCyHE52hA6           Liam Payne          78   \n",
      "3  7gAppWoH7pcYmphCVTXkzs            The Vamps          76   \n",
      "4  5Rl15oVamLq7FbSb0NNBNy  5 Seconds of Summer          86   \n",
      "\n",
      "                                     uri  \n",
      "0  spotify:artist:1Hsdzj7Dlq2I7tHP7501T4  \n",
      "1  spotify:artist:5ZsFI1h6hIdQRw2ti0hz81  \n",
      "2  spotify:artist:5pUo3fmmHT8bhCyHE52hA6  \n",
      "3  spotify:artist:7gAppWoH7pcYmphCVTXkzs  \n",
      "4  spotify:artist:5Rl15oVamLq7FbSb0NNBNy  \n"
     ]
    }
   ],
   "source": [
    "relart  = relart[[ 'followers', 'genres','id','name','popularity','uri']]\n",
    "allart = relart.append(artists)\n",
    "allart = allart.drop_duplicates(subset = ['id'])\n",
    "\n",
    "\n",
    "print(allart.head())\n",
    "allart.columns = ['followers', 'genres','spotify id','Label','popularity','uri']\n",
    "strgnrs = ['_'.join(i) for i in allart['genres']]\n",
    "allart['strgnrs'] = strgnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allart.to_csv('artists_nodes_gephi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist_data.columns = ['followers_source','genres_source','id_source','Source','popularity_source',\n",
    "                                  'uri_source','followers_related', 'genres_related','id_related', 'Target',\n",
    "                                   'popularity_related','uri_related']\n",
    "all_artist_data.to_csv('artists_edges_gephi.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I now have more data on artists (including related artists) than just the genres, I also make subsets of the artists data that fall under a few example genres. Any artist that was tagged with 'funk' would be included in this dataset, I will use gephi to understand communities of related artists this way. This isn't particularly scientific, but as a music nerd, it's pretty fun to see! the nodes are sized according to the number of spotify followers they have. The node colors are according to a community detection algorithm implemented by gephi. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funk\n",
    "![image.png](funk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "directed_artist = all_artist_data.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres_source'].apply(lambda x: 'funk' in x)\n",
    "funk = directed_artist.loc[source_mask]\n",
    "funk.to_csv('funk_source.csv',index = False)\n",
    "directed_artist = allart.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres'].apply(lambda x: 'funk' in x)\n",
    "funknodes = directed_artist.loc[source_mask]\n",
    "funknodes['Id'] = funknodes['Label'].copy()\n",
    "funknodes.to_csv('funk_source_nodes.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psych Rock\n",
    "![image.png](psychrock.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "directed_artist = all_artist_data.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres_source'].apply(lambda x: 'psychedelic rock' in x)\n",
    "psychrock = directed_artist.loc[source_mask]\n",
    "psychrock.to_csv('psychrock_source.csv',index = False)\n",
    "directed_artist = allart.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres'].apply(lambda x: 'psychedelic rock' in x)\n",
    "psychrocknodes = directed_artist.loc[source_mask]\n",
    "psychrocknodes['Id'] = psychrocknodes['Label'].copy()\n",
    "psychrocknodes.to_csv('psychrocknodes_source_nodes.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Rock\n",
    "\n",
    "![image.png](classicrock.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "directed_artist = all_artist_data.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres_source'].apply(lambda x: 'classic rock' in x)\n",
    "classicrock = directed_artist.loc[source_mask]\n",
    "classicrock.to_csv('classicrock_source.csv',index = False)\n",
    "directed_artist = allart.reset_index(drop = True)\n",
    "source_mask = directed_artist['genres'].apply(lambda x: 'classic rock' in x)\n",
    "classicrocknodes = directed_artist.loc[source_mask]\n",
    "classicrocknodes['Id'] = classicrocknodes['Label'].copy()\n",
    "classicrocknodes.to_csv('classicrock_source_nodes.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I seperate the genre tags and create a adjacency matrix that counts how many times each combination of 2 genres has occured in the netwrok, it is a pretty matrix as the density of network is pretty low. Part 2 contains the analysis of the larger Genres network along with important metrics and comparing community detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dance pop', 'pop')\n"
     ]
    }
   ],
   "source": [
    "gnrs = [i for i in allart['genres'] if i!= []]\n",
    "c = [list(itertools.combinations(i,2)) for i in gnrs]\n",
    "a = list(itertools.chain.from_iterable((i, i[::-1]) for c_ in c for i in c_))\n",
    "dfa = pd.DataFrame(a)\n",
    "dfgenrs = pd.pivot_table(dfa, index=0, columns=1, aggfunc='size', fill_value=0)\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.to_csv('network_nodes_final.csv',index = False)\n",
    "dfgenrs.to_csv('network_matrix_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
